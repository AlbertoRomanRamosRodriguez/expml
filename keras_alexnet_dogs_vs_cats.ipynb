{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras example AlexNet on Dogs vs Cats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the HDF5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import dogs_vs_cats_config as config\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras_example.preprocessing.aspectawareprocessor import AspectAwareProcessor\n",
    "from keras_example import HDF5DatasetWriter\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import json\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPaths = list(paths.list_images(config.IMAGES_PATH))\n",
    "trainLabels = [p.split(os.paths.sep)[-1].split(\".\")[0] \n",
    "    for p in trainPaths]\n",
    "\n",
    "le = LabelEncoder()\n",
    "trainLabels = le.fit_transform(trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainPaths, testPaths,trainLabels,testLabels) = train_test_split(\n",
    "    trainPaths, \n",
    "    trainLabels,\n",
    "    test_size=config.NUM_TEST_IMAGES,\n",
    "    stratify=trainLabels, \n",
    "    random_state = 42)\n",
    "\n",
    "(trainPaths, valPaths,trainLabels,valLabels) = train_test_split(\n",
    "    trainPaths, \n",
    "    trainLabels,\n",
    "    test_size=config.NUM_VAL_IMAGES,\n",
    "    stratify=trainLabels, \n",
    "    random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ('train', trainPaths, trainLabels, config.TRAIN_HDF5),\n",
    "    ('val', valPaths, valLabels, config.VAL_HDF5),\n",
    "    ('test', testPaths, testLabels, config.TEST_HDF5),\n",
    "]\n",
    "\n",
    "aap = AspectAwareProcessor(256,256)\n",
    "(R,G,B) = ([],[],[])\n",
    "\n",
    "for (dType, paths, labels, outputPath) in datasets:\n",
    "    print(f\"[INFO] building {outputPath}\")\n",
    "    writer = HDF5DatasetWriter((len(paths), 256,256,3), outputPath)\n",
    "\n",
    "    widgets = [\n",
    "        f\"Building Dataset {dType}: \",\n",
    "        progressbar.Percentage(),\n",
    "        \" \",\n",
    "        progressbar.Bar(),\n",
    "        \" \",\n",
    "        progressbar.ETA()\n",
    "    ]\n",
    "\n",
    "    pbar = progressbar.ProgressBar(\n",
    "        maxval=len(paths),\n",
    "        widgets=widgets\n",
    "        ).start()\n",
    "    \n",
    "    for (i, (path,label)) in enumerate(zip(paths, labels)):\n",
    "        image = cv2.imread(path)\n",
    "        image = aap.preprocess(image)\n",
    "\n",
    "        if dType == \"train\":\n",
    "            (b,g,r) = cv2.mean(image)[:3]\n",
    "            R.append(r)\n",
    "            G.append(g)\n",
    "            B.append(b)\n",
    "        \n",
    "        writer.add([image], [label])\n",
    "        pbar.update()\n",
    "    \n",
    "    pbar.finish()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] serializing means...\")\n",
    "D = {\n",
    "    \"R\": np.mean(R),\n",
    "    \"G\": np.mean(G),\n",
    "    \"B\": np.mean(B)\n",
    "}\n",
    "\n",
    "with open(config.DATASET_MEAN, \"w\") as f:\n",
    "    f.write(json.dumps(D))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import dogs_vs_cats_config\n",
    "\n",
    "from keras_example.preprocessing.imagetoarrayprocessor import ImageToArrayPreprocessor\n",
    "from keras_example.preprocessing.simplepreprocessor import SimpleProcessor\n",
    "from keras_example.preprocessing.patchpreprocessor import PatchPreprocessor\n",
    "from keras_example.preprocessing.meanpreprocessor import MeanPreprocessor\n",
    "\n",
    "from keras_example.callbacks.trainingmonitor import TrainingMonitor\n",
    "\n",
    "from keras_example.io.hdf5datasetgenerator import HDF5DatasetGenerator\n",
    "\n",
    "from keras_example.nn.conv.alexnet import AlexNet\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20, \n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2, \n",
    "    shear_range=0.15, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = json.loads(open(config.DATASET_MEAN).read())\n",
    "\n",
    "sp = SimpleProcessor(227,227)\n",
    "pp = PatchPreprocessor(227,227)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGen = HDF5DatasetGenerator(\n",
    "    config.TRAIN_HDF5,\n",
    "    128,\n",
    "    aug=aug,\n",
    "    preprocessors=[pp, mp, iap],\n",
    "    classes=2\n",
    ")\n",
    "\n",
    "valGen = HDF5DatasetGenerator(\n",
    "    config.TRAIN_HDF5,\n",
    "    128,\n",
    "    aug=aug,\n",
    "    preprocessors=[sp, mp, iap],\n",
    "    classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] compiling model ...\")\n",
    "opt = Adam(lr=1e-3)\n",
    "model = AlexNet.build(\n",
    "    width=227,\n",
    "    height=227,\n",
    "    depth=3,\n",
    "    classes=2,\n",
    "    reg=0.0002    \n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = \"binary_crossentropy\",\n",
    "    optimizer=opt\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "path = os.path.sep.join(\n",
    "    [config.OUTPUT_PATH,\n",
    "    f\"{os.getpgid()}\"]\n",
    ")\n",
    "\n",
    "callbacks = [TrainingMonitor(path)]\n",
    "\n",
    "print(\"[INFO] training model ...\")\n",
    "\n",
    "H =  model.fit_generator(\n",
    "    trainGen.generator(),\n",
    "    steps_per_epoch=trainGen.numImages // 128,\n",
    "    validation_data=valGen.generator(),\n",
    "    validation_steps=valGen.numImages // 128,\n",
    "    epochs=75,\n",
    "    max_queue_size=10,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] serializing model ...\")\n",
    "model.save(config.MODEL_PATH, overwrite=True)\n",
    "\n",
    "trainGen.close()\n",
    "valGen.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e551f31eb65be6f81ef744b09e589319bc7597989a590509a727060f7a3aaf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
